{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujatasahoo/Predictive-Modeling/blob/main/sujata__LS_DS_214_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK93oVkUQWpJ"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poJczAtjQWpP"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymDuUDVJQWpR"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from category_encoders import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CPLHez86TL4",
        "outputId": "0b257faa-ffb1-49c0-a828-32ccb85fbe90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1RlABubQWpS"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YCaSgFaQWpT"
      },
      "outputs": [],
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    \n",
        "    df = df.fillna(0)\n",
        "    df = df.replace({ \"X\": \"1\", \"x\":\"1\",\"No\":\"0\"})\n",
        "    # Burrito\n",
        "    burrito_1 = ['california', 'asada', 'surf', 'carnitas']\n",
        "    for i in burrito_1:\n",
        "      df[i] = df['Burrito'].str.lower().str.contains(i).astype(int)\n",
        "      # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall', 'Burrito'], inplace = True)\n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrVf2uPHQWpU"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZo_MxoQWpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5250aa-af37-4f77-9eab-22cc037e9bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 421 entries, 2016-01-18 to 2019-08-27\n",
            "Data columns (total 62 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Yelp            421 non-null    float64\n",
            " 1   Google          421 non-null    float64\n",
            " 2   Chips           421 non-null    object \n",
            " 3   Cost            421 non-null    float64\n",
            " 4   Hunger          421 non-null    float64\n",
            " 5   Mass (g)        421 non-null    float64\n",
            " 6   Density (g/mL)  421 non-null    float64\n",
            " 7   Length          421 non-null    float64\n",
            " 8   Circum          421 non-null    float64\n",
            " 9   Volume          421 non-null    float64\n",
            " 10  Tortilla        421 non-null    float64\n",
            " 11  Temp            421 non-null    float64\n",
            " 12  Meat            421 non-null    float64\n",
            " 13  Fillings        421 non-null    float64\n",
            " 14  Meat:filling    421 non-null    float64\n",
            " 15  Uniformity      421 non-null    float64\n",
            " 16  Salsa           421 non-null    float64\n",
            " 17  Synergy         421 non-null    float64\n",
            " 18  Wrap            421 non-null    float64\n",
            " 19  Reviewer        421 non-null    object \n",
            " 20  Unreliable      421 non-null    object \n",
            " 21  NonSD           421 non-null    object \n",
            " 22  Beef            421 non-null    object \n",
            " 23  Pico            421 non-null    object \n",
            " 24  Guac            421 non-null    object \n",
            " 25  Cheese          421 non-null    object \n",
            " 26  Fries           421 non-null    object \n",
            " 27  Sour cream      421 non-null    object \n",
            " 28  Pork            421 non-null    object \n",
            " 29  Chicken         421 non-null    object \n",
            " 30  Shrimp          421 non-null    object \n",
            " 31  Fish            421 non-null    object \n",
            " 32  Rice            421 non-null    object \n",
            " 33  Beans           421 non-null    object \n",
            " 34  Lettuce         421 non-null    object \n",
            " 35  Tomato          421 non-null    object \n",
            " 36  Bell peper      421 non-null    object \n",
            " 37  Carrots         421 non-null    object \n",
            " 38  Cabbage         421 non-null    object \n",
            " 39  Sauce           421 non-null    object \n",
            " 40  Salsa.1         421 non-null    object \n",
            " 41  Cilantro        421 non-null    object \n",
            " 42  Onion           421 non-null    object \n",
            " 43  Taquito         421 non-null    object \n",
            " 44  Pineapple       421 non-null    object \n",
            " 45  Ham             421 non-null    object \n",
            " 46  Chile relleno   421 non-null    object \n",
            " 47  Nopales         421 non-null    object \n",
            " 48  Lobster         421 non-null    object \n",
            " 49  Queso           421 non-null    float64\n",
            " 50  Egg             421 non-null    object \n",
            " 51  Mushroom        421 non-null    object \n",
            " 52  Bacon           421 non-null    object \n",
            " 53  Sushi           421 non-null    object \n",
            " 54  Avocado         421 non-null    object \n",
            " 55  Corn            421 non-null    object \n",
            " 56  Zucchini        421 non-null    object \n",
            " 57  Great           421 non-null    int64  \n",
            " 58  california      421 non-null    int64  \n",
            " 59  asada           421 non-null    int64  \n",
            " 60  surf            421 non-null    int64  \n",
            " 61  carnitas        421 non-null    int64  \n",
            "dtypes: float64(19), int64(5), object(38)\n",
            "memory usage: 207.2+ KB\n"
          ]
        }
      ],
      "source": [
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "df = wrangle(filepath)\n",
        "df.info()\n",
        "#df.select_dtype('object').info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "I4m0GKGbwKZS",
        "outputId": "a30f869b-40b3-4a1e-827e-832334e040de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3a2ac530-124a-47da-80f7-963e368e9c4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Reviewer</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "      <th>california</th>\n",
              "      <th>asada</th>\n",
              "      <th>surf</th>\n",
              "      <th>carnitas</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Emily</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Scott</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a2ac530-124a-47da-80f7-963e368e9c4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a2ac530-124a-47da-80f7-963e368e9c4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a2ac530-124a-47da-80f7-963e368e9c4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Yelp  Google Chips  Cost  ...  california  asada  surf  carnitas\n",
              "Date                                  ...                                   \n",
              "2016-01-18   3.5     4.2     0  6.49  ...           1      0     0         0\n",
              "2016-01-24   3.5     3.3     0  5.45  ...           1      0     0         0\n",
              "2016-01-24   0.0     0.0     0  4.85  ...           0      0     0         1\n",
              "2016-01-24   0.0     0.0     0  5.25  ...           0      1     0         0\n",
              "2016-01-27   4.0     3.8     1  6.59  ...           1      0     0         0\n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpYbMvmaQWpV"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vemx0GCNQWpW"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above.\n",
        "#df['Burrito']\n",
        "#burrito_1 = ['california', 'asada', 'surf', 'carnitas']\n",
        "#for i in burrito_1:\n",
        "  #df[i] = df['Burrito'].str.lower().str.contains(i).astype(int)\n",
        "#df[['california', 'asada', 'surf', 'carnitas']].head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5FzfuKQQWpX"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUWQtmdkQWpY"
      },
      "outputs": [],
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwkC8GnxQWpZ"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iqSd8VbQWpZ"
      },
      "outputs": [],
      "source": [
        "target ='Great' \n",
        "X = df.drop(columns= 'Great')\n",
        "y = df[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMK0vMI6QWpa"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sY4cfJjiQWpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec1c999-07f1-4987-8aa3-aca1a1fc6e0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(383, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "cutoff = '2018'\n",
        "mask = X.index < cutoff\n",
        "X_train, y_train = X.loc[mask], y.loc[mask]\n",
        "X_test, y_test = X.loc[~mask], y.loc[~mask]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LQueG9VQWpb"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmpJ-lawQWpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "014fe938-86e2-44c1-88c0-84248c990b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Accuracy Score: 0.5822454308093995\n"
          ]
        }
      ],
      "source": [
        "y_train.value_counts(normalize = True)\n",
        "baseline_acc = y_train.value_counts(normalize = True).max()\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha9zyQzJQWpb"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-xRHzKvQWpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d11a9e-a2ab-43ac-f948-9b15a96f9fb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('onehotencoder',\n",
              "                 OneHotEncoder(cols=['Chips', 'Reviewer', 'Unreliable', 'NonSD',\n",
              "                                     'Beef', 'Pico', 'Guac', 'Cheese', 'Fries',\n",
              "                                     'Sour cream', 'Pork', 'Chicken', 'Shrimp',\n",
              "                                     'Fish', 'Rice', 'Beans', 'Lettuce',\n",
              "                                     'Tomato', 'Bell peper', 'Carrots',\n",
              "                                     'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro',\n",
              "                                     'Onion', 'Taquito', 'Pineapple', 'Ham',\n",
              "                                     'Chile relleno', 'Nopales', ...],\n",
              "                               use_cat_names=True)),\n",
              "                ('simpleimputer', SimpleImputer()),\n",
              "                ('standardscaler', StandardScaler()),\n",
              "                ('logisticregression', LogisticRegression())])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model_logr = make_pipeline(OneHotEncoder(use_cat_names=True),\n",
        "                           SimpleImputer(strategy ='mean'),\n",
        "                           StandardScaler(), LogisticRegression())\n",
        "model_logr.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uil-zGYsQWpc"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3m01riVQWpc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59f0bbe-7ebe-4f8c-95a4-b5f63894df21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE: 0.9451697127937336\n",
            "Test MAE: 0.7631578947368421\n"
          ]
        }
      ],
      "source": [
        "training_acc = model_logr.score(X_train, y_train)\n",
        "test_acc = model_logr.score(X_test, y_test)\n",
        "\n",
        "print('Training MAE:', training_acc)\n",
        "print('Test MAE:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE6d-kFlQWpc"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sIUUJVxQWpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5450a35-f97c-4b31-ad3f-b464a066281d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Queso                0.000000\n",
              "Reviewer_Rob L       0.000015\n",
              "Reviewer_Karl        0.000083\n",
              "Reviewer_Damien B    0.000086\n",
              "Reviewer_Erik K      0.000087\n",
              "                       ...   \n",
              "Reviewer_Elynn       0.937879\n",
              "Meat                 1.076301\n",
              "Fillings             1.081507\n",
              "Meat:filling         1.085705\n",
              "Synergy              2.942046\n",
              "Length: 191, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Create your horizontal barchart here.\n",
        "coefficients = model_logr.named_steps['logisticregression'].coef_[0]\n",
        "features = model_logr.named_steps['onehotencoder'].get_feature_names()\n",
        "feat_impt = pd.Series(coefficients, index = features).sort_values(key = abs)\n",
        "feat_impt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_impt.tail(10).plot(kind = 'barh')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "-8hp4oa6N59k",
        "outputId": "800f74b4-ceb5-4452-f2cb-81c95a312ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f093c323f50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JmzMWK2QWpd"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNeHb7TIQWpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a9aff7-9430-4862-f54f-663a48e8a05c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "model_logr.predict(X_test)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_logr.predict_proba(X_test)[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEyoZ0YvG-Iq",
        "outputId": "7209e253-d802-482f-a3cd-27750cc2b0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.23938390e-05, 9.99917606e-01],\n",
              "       [1.32018818e-03, 9.98679812e-01],\n",
              "       [3.00696062e-02, 9.69930394e-01],\n",
              "       [3.35848617e-06, 9.99996642e-01],\n",
              "       [9.97465473e-01, 2.53452687e-03]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_logr.predict(X_test).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLa4qazmcAbt",
        "outputId": "20b01fbb-2185-4490-f3d2-2b23591a67ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38,)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_logr.predict_proba(X_test).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SXF0FTzb5vp",
        "outputId": "66ebe371-483e-4a50-a07e-6fc42347d5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkfly2hQWpd"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "```\n",
        "The predict and predict_proba are both numpy.ndarray.\n",
        "predict Shape = (38,)--38 predictions.\n",
        "Predict_proba shape = (38, 2)- sum acros the column is one and all\n",
        "predict probability...degree of certainty that burrito is great or not.\n",
        "\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sujata_ LS_DS_214_solution.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}